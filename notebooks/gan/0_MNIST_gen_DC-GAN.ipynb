{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErQP1Nw0EAyI"
      },
      "source": [
        "[![Made withJupyter](https://img.shields.io/badge/Made%20with-Jupyter-orange?style=for-the-badge&logo=Jupyter)](https://jupyter.org/try)\n",
        "\n",
        "# MNIST generation with DC-GAN\n",
        "\n",
        "This notebook is freely inspired by the [TensorFlow tutorial](https://www.tensorflow.org/tutorials/generative/dcgan) on Deep Convolutional Generative Adversarial Network (DC-GAN). The code is written using the [Keras Sequential API](https://www.tensorflow.org/guide/keras/sequential_model) to build the adversarial networks and the [`tf-gen-models` package](https://pypi.org/project/tf-gen-models/) to implement and run the training procedure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nmsCNTgEAyN"
      },
      "source": [
        "## What are GANs?\n",
        "\n",
        "Generative Adversarial Networks [[1](https://arxiv.org/abs/1406.2661)] are a powerful class of _generative models_ based on the simultaneous training of two neural networks:\n",
        "\n",
        "*  the **discriminator network** ($D$) is trained to distinguish the generator output from the reference dataset;\n",
        "* while the **generator network** ($G$) is trained to reproduce the reference dataset trying to fake the discriminator.\n",
        "\n",
        "The goal is that $D$ optimally discriminates on the origin of the two samples, and simultaneously the training procedure for $G$ is to maximize the _probability_ of $D$ making a mistake. This framework corresponds to a **minimax two-player game** [[1](https://arxiv.org/abs/1406.2661)]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DELqq4dkWeeb"
      },
      "source": [
        "## Mathematical details\n",
        "\n",
        "The generator $G(z)$, fed by elements $z$ sampled according to a known distribution $p_z$ (typically gaussian), maps the **latent space** $\\mathcal{Z}$ to the reference dataset $\\mathcal{X}$, inducing a distribution $p_\\rm{gen}$ trained to match with the target distribution $p_\\rm{ref}$. The discriminator $D(x)$ outputs a single scalar, readable as the **probability** that $x$ comes from the reference dataset rather than $G$. Then, the optimization problem corresponds to train $D$ to maximize the probability of correct labelling, and simultaneously training $G$ to minimize $\\log(1 - D(G(z)))$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q6t5VvqpFtU"
      },
      "source": [
        "Defining the **loss function** $\\mathcal{L}_\\rm{GAN}$ as follows\n",
        "\n",
        "<center>$\\mathcal{L}_\\rm{GAN} = \\mathbb{E}_{x \\sim p_\\rm{ref}} \\left[ \\log{D(x)} \\right] + \\mathbb{E}_{z \\sim p_\\rm{gen}} \\left[ \\log(1 - D(G(z))) \\right]$</center>\n",
        "\n",
        "the _minimax game_ can be written in this form:\n",
        "\n",
        "<center>$\\min_G \\max_D \\mathcal{L}_\\rm{GAN}$</center>\n",
        "\n",
        "A unique solution exists, with $G$ recovering the reference distribution $p_\\rm{ref}$ and $D$ equal to 1/2 everywhere [[1](https://arxiv.org/abs/1406.2661)]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_t0arG3qy0I"
      },
      "source": [
        "Traditional GAN systems suffer from many issues, particularly during the training phase:\n",
        "\n",
        "* generator _collapsing_ to produce only a single sample or a small family of very similar samples;\n",
        "* generator and discriminator _oscillating_ during training rather than converging to a fixed point;\n",
        "* if _imbalance_ between the two agents occurs, the system doesnâ€™t learn.\n",
        "\n",
        "All these issues are related to the **vanishing gradient** problem. In order to fix it, one can add _continuous noise_ to both discriminator and generator. This trick allows to learn thanks to a non-zero gradient [[2](https://arxiv.org/abs/1701.04862)]. The `GAN` class provided by the `tf-gen-models` package implements a training procedure stabilized by **noise injection** as just described."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8pTLAH5Xj_S"
      },
      "source": [
        "## What are GANs used for?\n",
        "\n",
        "GANs are widely used as **generative image model** thanks to their capacity in reproducing highly faithful and diverse images with models learned directly from data [[3](https://arxiv.org/abs/1809.11096)]. The notebook will test GANs in generating *handwritten digits* accordingly to the MNIST dataset. In this example, the latent space elements $z$ will be mapped in a 28x28 space representing the **pixel intensity** of digit images. Both generated images and reference ones will feed the discriminator, trained to distinguish real from fake input. This framework corresponds to the *deep convolutional version* of the minimax game described above [[4](https://arxiv.org/abs/1511.06434)].\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/mbarbetti/tf-gen-models/main/.github/images/gan/gan_scheme.png\" width=\"800\"/>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSP-a5WjEAyP"
      },
      "source": [
        "## Let's code!\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/mbarbetti/tf-gen-models/blob/main/notebooks/gan/0_MNIST_gen_DC-GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/mbarbetti/tf-gen-models/blob/main/notebooks/gan/0_MNIST_gen_DC-GAN.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qGylgSQEAyQ"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MtLDHwjKSXQ",
        "outputId": "cc410294-00b5-403d-ac4a-b3215466458c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-gen-models\n",
            "  Downloading tf_gen_models-0.0.2-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: tf-gen-models\n",
            "Successfully installed tf-gen-models-0.0.2\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio) (7.1.2)\n",
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-zuir6q5i\n",
            "  Running command git clone -q https://github.com/tensorflow/docs /tmp/pip-req-build-zuir6q5i\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (1.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (2.11.3)\n",
            "Requirement already satisfied: protobuf>=3.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.13)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.14->tensorflow-docs==0.0.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.0.1)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=173744 sha256=17cc06c27c0b3bcb69843055687bb99f735ffb8b17c7cde59199c1b5a8fd5679\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g3dlnx1u/wheels/cc/c4/d8/5341e93b6376c5c929c49469fce21155eb69cef1a4da4ce32c\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: tensorflow-docs\n",
            "Successfully installed tensorflow-docs-0.0.0.dev0\n"
          ]
        }
      ],
      "source": [
        "## to run the training\n",
        "!pip install tf-gen-models\n",
        "\n",
        "## to generate GIFs\n",
        "!pip install imageio\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dH1Gx2RGEAyQ"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "import glob\n",
        "import imageio\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from tf_gen_models.algorithms.gan import GAN\n",
        "from tf_gen_models.callbacks import GanExpLrScheduler, ImageSaver, ModelSaver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eyY7WJLzbgd4",
        "outputId": "05505633-8b83-4efc-aef6-3628c16584a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KCfg-3gEAyS"
      },
      "source": [
        "### Load and prepare the dataset\n",
        "\n",
        "We will use the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) to train the generator and the discriminator. Overcoming the minimax game, the generator will be able to generate handwritten digits resembling the MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wEzC_bgDEAyS",
        "outputId": "57af29f9-9fcc-4934-d1c2-377e3dcbc006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_img, _), (test_img, _) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z5al5WYcnVk"
      },
      "source": [
        "The dataset counts 70000 handwritten digits, arranged as a **training set** of 60000 examples and a **test set** of 10000 examples. Each instance corresponds to a 28x28 image with pixel intensity bounded between 0 and 255. To ease the neural networks training, the images should be normalized in a smaller range (i.e. between 0 and 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ol43oL3SEAyT"
      },
      "outputs": [],
      "source": [
        "train_img = train_img . reshape ( train_img.shape[0], 28, 28, 1 ) \\\n",
        "                      . astype ( np.float32 )\n",
        "train_img = ( train_img - 127.5) / 127.5   # pixel intensity in [-1,1]\n",
        "\n",
        "test_img = test_img . reshape ( test_img.shape[0], 28, 28, 1 ) \\\n",
        "                    . astype ( np.float32 ) \n",
        "test_img = ( test_img - 127.5) / 127.5   # pixel intensity in [-1,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n5I5nYccnVk"
      },
      "source": [
        "Here are some examples of handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "ikQBxVFpEAyU",
        "outputId": "d6619052-4904-4095-9f51-7722d9cc8f69"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x2000 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "start = np.random.randint (0, 60000)\n",
        "\n",
        "plt.figure (figsize = (10,20), dpi = 100)\n",
        "for i in range(10):\n",
        "  plt.subplot (1, 10, i+1)\n",
        "  plt.imshow (train_img[start + i,:,:,0], cmap = \"gray\")\n",
        "  plt.axis (\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pn0XRMccnVl"
      },
      "source": [
        "To help the neural networks to consume data efficiently during the training procedure, it's useful prepare it within [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BQJpFT-kEAyW"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UQy0sQisEAyX"
      },
      "outputs": [],
      "source": [
        "train_ds = ( \n",
        "  tf.data.Dataset.from_tensor_slices ( train_img )\n",
        "  .shuffle ( BUFFER_SIZE )                       # shuffle all the images\n",
        "  .batch ( BATCH_SIZE, drop_remainder = True )   # mini-batch splitting\n",
        "  #.cache()                                       # cache the dataset\n",
        "  #.prefetch ( tf.data.AUTOTUNE )   # pre-prepare data to be consumed\n",
        ")\n",
        "\n",
        "test_ds = ( \n",
        "  tf.data.Dataset.from_tensor_slices ( test_img )\n",
        "  .shuffle ( BUFFER_SIZE )                       # shuffle all the images\n",
        "  .batch ( BATCH_SIZE, drop_remainder = True )   # mini-batch splitting\n",
        "  #.cache()                                       # cache the dataset\n",
        "  #.prefetch ( tf.data.AUTOTUNE )   # pre-prepare data to be consumed\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbqb9IyCEAyX"
      },
      "source": [
        "### Create the adversarial players\n",
        "\n",
        "Both the generator and the discriminator are defined using the [Keras Sequential API](https://www.tensorflow.org/guide/keras/sequential_model)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMLOrvq6EAyY"
      },
      "source": [
        "#### The generator\n",
        "\n",
        "The generator uses [`tf.keras.layers.Conv2DTranspose`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose) (sometimes called **deconvolutional**) layers to produce an image from the latent space $\\mathcal{Z}$. Start with a `Dense` layer that takes $z$ elements as input, then upsample several times until to reach the desired image size of 28x28x1. Notice the [`tf.keras.layers.LeakyReLU`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU) activation for each layer, except the output layer which uses $\\tanh$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Lf5Qh97FcnVn"
      },
      "outputs": [],
      "source": [
        "LATENT_DIM = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mbdo1p09EAyY"
      },
      "outputs": [],
      "source": [
        "generator = Sequential ( name = \"generator\" )\n",
        "\n",
        "generator . add ( layers.Dense ( 7 * 7 * 256, use_bias = False, input_shape = (LATENT_DIM,) ) )\n",
        "generator . add ( layers.BatchNormalization() )\n",
        "generator . add ( layers.LeakyReLU ( alpha = 0.2 ) )\n",
        "\n",
        "generator . add ( layers.Reshape ( (7, 7, 256) ) )\n",
        "\n",
        "generator . add ( layers.Conv2DTranspose ( 128, (5, 5), strides = (1, 1), padding = \"same\", use_bias = False ) )\n",
        "generator . add ( layers.BatchNormalization() )\n",
        "generator . add ( layers.LeakyReLU ( alpha = 0.2 ) )\n",
        "\n",
        "generator . add ( layers.Conv2DTranspose ( 64, (5, 5), strides = (2, 2), padding = \"same\", use_bias = False ) )\n",
        "generator . add ( layers.BatchNormalization() )\n",
        "generator . add ( layers.LeakyReLU ( alpha = 0.2 ) )\n",
        "\n",
        "generator . add ( layers.Conv2DTranspose ( 1, (5, 5), strides = (2, 2), padding = \"same\", use_bias = False, activation = \"tanh\" ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g-3KGHAcnVn"
      },
      "source": [
        "Use the (as yet untrained) generator to create an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "1eFSOlqdcjWp",
        "outputId": "b8abd50e-4f0e-4237-8fc1-1ac3133c5506"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "z = tf.random.normal ( shape = [1, 100] )\n",
        "gen_image = generator ( z, training = False )\n",
        "\n",
        "plt.figure (figsize = (4,4), dpi = 100)\n",
        "plt.imshow (gen_image[0, :, :, 0], cmap = \"gray\")\n",
        "plt.axis (\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQbt1vY4EAyZ"
      },
      "source": [
        "#### The discriminator\n",
        "\n",
        "The discriminator is a CNN-based image classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "koh-MPIFEAyZ"
      },
      "outputs": [],
      "source": [
        "discriminator = Sequential ( name = \"discriminator\" )\n",
        "    \n",
        "discriminator . add ( layers.Conv2D ( 64, (5, 5), strides = (2, 2), padding = \"same\", input_shape = [28, 28, 1] ) )\n",
        "discriminator . add ( layers.LeakyReLU ( alpha = 0.2 ) )\n",
        "discriminator . add ( layers.Dropout (0.3) )\n",
        "\n",
        "discriminator . add ( layers.Conv2D ( 128, (5, 5), strides = (2, 2), padding = \"same\" ) )\n",
        "discriminator . add ( layers.LeakyReLU ( alpha = 0.2 ) )\n",
        "discriminator . add ( layers.Dropout (0.3) )\n",
        "\n",
        "discriminator . add ( layers.Flatten() )\n",
        "discriminator . add ( layers.Dense ( 1, activation = \"sigmoid\" ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XdTJqRGcnVo"
      },
      "source": [
        "Use the (as yet untrained) discriminator to classify the generated images as real or fake. The model will be trained to output the probability that the input is a real image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEBqc_7Ac6Ir",
        "outputId": "b2e449f7-c33c-4db9-ac4e-f3968cbc0e30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5003296]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "discriminator ( gen_image ) . numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amVDgDLMdHmd"
      },
      "source": [
        "### Training procedure\n",
        "\n",
        "The training procedure is implemented through the `GAN` class provided by the [`tf-gen-models` package](https://pypi.org/project/tf-gen-models/). The network learning is driven by the loss function previously described [[1](https://arxiv.org/abs/1406.2661)], while the training is stabilized thanks to a noise injection [[2](https://arxiv.org/abs/1701.04862)]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Vqa1qTalEAyZ"
      },
      "outputs": [],
      "source": [
        "gan = GAN (generator, discriminator, latent_dim = LATENT_DIM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMltFvq-cnVp"
      },
      "source": [
        "The architecture chosen for the two players can be recovered through the `summary()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k3cEhtsScnVp",
        "outputId": "53019538-f9fb-42ce-f049-7475a119e6a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12544)             1254400   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 12544)            50176     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 12544)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819200    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204800    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1600      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,330,944\n",
            "Trainable params: 2,305,472\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n",
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        1664      \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "gan . summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC5_gjVmcnVq"
      },
      "source": [
        "#### Generator and discriminator optimizers\n",
        "\n",
        "The discriminator and the generator **optimizers** are different since we will train two networks separately (even if simultaneously)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ziL3VMkvcnVq"
      },
      "outputs": [],
      "source": [
        "G_LR = 1e-4\n",
        "D_LR = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fhgkiczeEAya"
      },
      "outputs": [],
      "source": [
        "g_opt = tf.keras.optimizers.Adam ( G_LR )\n",
        "d_opt = tf.keras.optimizers.Adam ( D_LR )\n",
        "\n",
        "gan . compile ( g_optimizer = g_opt , \n",
        "                d_optimizer = d_opt , \n",
        "                g_updt_per_batch = 1 , \n",
        "                d_updt_per_batch = 1 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG_A7Pt3cnVr"
      },
      "source": [
        "In order to reach the minimum _quickly_ and _safely_, the learning rate should be decreased gradually during the training. The `GanLrScheduler` class implements an **exponential decay**, where `factor` represents the decay rate and `step` corresponds to the decay step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_L1iSZHEcnVr"
      },
      "outputs": [],
      "source": [
        "lr_sched = GanExpLrScheduler ( factor = 0.95, step = 10 )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom callbacks\n",
        "\n",
        "A callback is a powerful tool to customize the behavior of a Keras model during training, evaluation, or inference. For instance, the `GanLrScheduler` class mentioned above inherits from the [`tf.keras.callbacks.Callback`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback) class. The `tf-gen-models` package offers more callbacks to customize the training procedure, like `ImageSaver` and `ModelSaver`:\n",
        "\n",
        "* `ImageSaver` allows to save the generator output (more precisely, a 4x4 matrix of digit images) once every `step` epochs;\n",
        "* `ModelSaver` allows to save a checkpoint of the generator and/or discriminator models once every `step` epochs.\n",
        "\n",
        "To learn more about custom callbacks, refers to the [TensorFlow guide](https://www.tensorflow.org/guide/keras/custom_callback)."
      ],
      "metadata": {
        "id": "Ess73WYogGXl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XG6p97JZcnVr"
      },
      "outputs": [],
      "source": [
        "img_saver = ImageSaver ( name = \"dc-gan\", step = 1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6SKL_vcfcnVr"
      },
      "outputs": [],
      "source": [
        "mod_saver = ModelSaver ( name = \"dc-gan\", step = 10 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AY0zMWHcnVr"
      },
      "source": [
        "#### Minimax game\n",
        "\n",
        "The `GAN` class inherits from the [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) and implements a [custom `fit()` function](https://keras.io/guides/customizing_what_happens_in_fit/). Calling the `fit()` method, every mini-batch of data the discriminator loss function is computed and network weights updated for `d_updt_per_batch` times, then the generator loss is computed and relative weights updated for `g_updt_per_batch` times. Note, training GANs can be _tricky_. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n",
        "\n",
        "At the beginning of the training, the generated images look like random noise. As training progresses, the generated digits will look increasingly real (even if **mode collapse** may occur). After about 50 epochs, they resemble MNIST digits. This may take about one minute / epoch with the default settings on [Google Colab](https://colab.research.google.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NJnq__TKcnVs"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "STEPS_PER_EPOCH = int ( len(train_img) / BATCH_SIZE )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "EKOe1ddQEAya",
        "outputId": "327a6573-9400-40d6-eff9-30d12d2dd4b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  7/234 [..............................] - ETA: 24:12 - mse: 0.9031 - g_loss: -0.3259 - d_loss: 0.3258 - g_lr: 1.0000e-04 - d_lr: 1.0000e-04"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-30df7442ae7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mlr_sched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_saver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_saver\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     verbose = 1 )\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train = gan . fit ( train_ds , \n",
        "                    epochs = EPOCHS ,\n",
        "                    steps_per_epoch = STEPS_PER_EPOCH ,\n",
        "                    validation_data = test_ds ,\n",
        "                    callbacks = [ lr_sched, img_saver, mod_saver ] ,\n",
        "                    verbose = 1 )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Learning and metric curves"
      ],
      "metadata": {
        "id": "l1qCLzyYiEU0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XrT26w9EAyb"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots (1, 2, figsize = (15,5), dpi = 100)\n",
        "plt.subplots_adjust (wspace = 0.2)\n",
        "\n",
        "ax[0] . set_title (\"Learning curves\", fontsize = 14)\n",
        "ax[0] . set_xlabel (\"Training epochs\", fontsize = 12)\n",
        "ax[0] . set_ylabel (f\"{gan.loss_name}\", fontsize = 12)\n",
        "ax[0] . plot (train.history[\"g_loss\"], linewidth = 1.5, color = \"coral\", label = \"generator\")\n",
        "ax[0] . plot (train.history[\"d_loss\"], linewidth = 1.5, color = \"dodgerblue\", label = \"discriminator\")\n",
        "ax[0] . legend (loc = \"upper right\", fontsize = 10)\n",
        "\n",
        "ax[1] . set_title (\"Metric curves\", fontsize = 14)\n",
        "ax[1] . set_xlabel (\"Training epochs\", fontsize = 12)\n",
        "ax[1] . set_ylabel (\"Mean square error\", fontsize = 12)\n",
        "ax[1] . plot (train.history[\"mse\"], linewidth = 1.5, color = \"forestgreen\", label = \"training set\")\n",
        "ax[1] . plot (train.history[\"val_mse\"], linewidth = 1.5, color = \"orangered\", label = \"validation set\")\n",
        "ax[1] . legend (loc = \"upper right\", fontsize = 10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a GIF"
      ],
      "metadata": {
        "id": "uxhyM-N6iKTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image (epoch):\n",
        "  return PIL.Image.open (f\"./images/dc-gan_ep{epoch:04d}.png\")"
      ],
      "metadata": {
        "id": "ChnbsDQFpuQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_image (EPOCHS)"
      ],
      "metadata": {
        "id": "Nt7Z8XiHqLwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `imageio` to create an animated gif using the images saved during training."
      ],
      "metadata": {
        "id": "ZHTZS7pyp4f1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mTl_2j8cnVs"
      },
      "outputs": [],
      "source": [
        "anim_file = \"dc-gan.gif\"\n",
        "\n",
        "with imageio.get_writer (anim_file, mode = \"I\") as writer:\n",
        "  filenames = glob.glob (\"./images/dc-gan_ep*.png\")\n",
        "  filenames = sorted (filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread (filename)\n",
        "    writer.append_data (image)\n",
        "  image = imageio.imread (filename)\n",
        "  writer.append_data (image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6MDDyhVcnVt"
      },
      "outputs": [],
      "source": [
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file (anim_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps\n",
        "\n",
        "To learn more about GANs see the [notebooks](https://github.com/mbarbetti/tf-gen-models/tree/main/notebooks) section of the `tf-gen-models` [GitHub repository](https://github.com/mbarbetti/tf-gen-models)."
      ],
      "metadata": {
        "id": "DdyBMcktpEBg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6JVj2UeEAyO"
      },
      "source": [
        "## References\n",
        "\n",
        "1.  I. J. Goodfellow _et al._, \"Generative Adversarial Nets\", [arXiv:1406.2661](https://arxiv.org/abs/1406.2661).\n",
        "2. M. Arjovsky and L. Bottou, \"Towards Principled Methods for Training Generative Adversarial Networks\", [arXiv:1701.04862](https://arxiv.org/abs/1701.04862).\n",
        "3. A. Brock, J. Donahue and K. Simonyan, \"Large Scale GAN Training for High Fidelity Natural Image Synthesis\", [arXiv:1809.11096](https://arxiv.org/abs/1809.11096).\n",
        "4. A. Radford, L. Metz and S. Chintala, \"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\", [arXiv:1511.06434](https://arxiv.org/abs/1511.06434)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "0_MNIST_gen_DC-GAN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "509037c093046b62af1066633923ed7457933c67876dee065b4ea60fb6ff9db7"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('tf-cpu': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}